{
    "collab_server" : "",
    "contents" : "# randomthoughtsonr.blogspot.nl/2016/11/image-classification-in-r-using-trained.html\n\nrm(list = ls())\n\nlibrary(reticulate)\nuse_condaenv(\"snakes\")\n\nlibrary(tensorflow)\n\nslim = tf$contrib$slim #Poor mans import tensorflow.contrib.slim as slim\ntf$reset_default_graph() # Better to start from scratch\n\n# We start with a placeholder tensor in which we later feed the images\n# The first index of the tensor counts the image number and the second to 4th index is for the width, height, color. Since we want to allow for an arbitrary number of images of arbitrary size, we leave these dimensions open.\nimages = tf$placeholder(tf$float32, shape(NULL, NULL, NULL, 3))\nimgs_scaled = tf$image$resize_images(images, shape(224,224))\n\n# Definition of the network\nlibrary(magrittr) \n# The last layer is the fc8 Tensor holding the logits of the 1000 classes\nfc8 = slim$conv2d(imgs_scaled, 64, shape(3,3), scope='vgg_16/conv1/conv1_1') %>% \n  slim$conv2d(64, shape(3,3), scope='vgg_16/conv1/conv1_2')  %>%\n  slim$max_pool2d( shape(2, 2), scope='vgg_16/pool1')  %>%\n  \n  slim$conv2d(128, shape(3,3), scope='vgg_16/conv2/conv2_1')  %>%\n  slim$conv2d(128, shape(3,3), scope='vgg_16/conv2/conv2_2')  %>%\n  slim$max_pool2d( shape(2, 2), scope='vgg_16/pool2')  %>%\n  \n  slim$conv2d(256, shape(3,3), scope='vgg_16/conv3/conv3_1')  %>%\n  slim$conv2d(256, shape(3,3), scope='vgg_16/conv3/conv3_2')  %>%\n  slim$conv2d(256, shape(3,3), scope='vgg_16/conv3/conv3_3')  %>%\n  slim$max_pool2d(shape(2, 2), scope='vgg_16/pool3')  %>%\n  \n  slim$conv2d(512, shape(3,3), scope='vgg_16/conv4/conv4_1')  %>%\n  slim$conv2d(512, shape(3,3), scope='vgg_16/conv4/conv4_2')  %>%\n  slim$conv2d(512, shape(3,3), scope='vgg_16/conv4/conv4_3')  %>%\n  slim$max_pool2d(shape(2, 2), scope='vgg_16/pool4')  %>%\n  \n  slim$conv2d(512, shape(3,3), scope='vgg_16/conv5/conv5_1')  %>%\n  slim$conv2d(512, shape(3,3), scope='vgg_16/conv5/conv5_2')  %>%\n  slim$conv2d(512, shape(3,3), scope='vgg_16/conv5/conv5_3')  %>%\n  slim$max_pool2d(shape(2, 2), scope='vgg_16/pool5')  %>%\n  \n  slim$conv2d(4096, shape(7, 7), padding='VALID', scope='vgg_16/fc6')  %>%\n  slim$conv2d(4096, shape(1, 1), scope='vgg_16/fc7') %>% \n  \n  # Setting the activation_fn=NULL does not work, so we get a ReLU\n  slim$conv2d(1000, shape(1, 1), scope='vgg_16/fc8')  %>%\n  tf$squeeze(shape(1, 2), name='vgg_16/fc8/squeezed')\n\n\n# visualise in tensorboard\ndir.create('tensorboard')\n\ntf$summary$FileWriter('tensorboard/vgg16', tf$get_default_graph())$close()\n\n# Loading the weights\nrestorer = tf$train$Saver()\nsess = tf$Session()\nrestorer$restore(sess, './vgg_16.ckpt')\n\n# loading the images\nlibrary(jpeg)\nimg1 <- readJPEG('images/apple.jpg')\nimg1 <- readJPEG('images/football.jpg')\nimg1 <- readJPEG('images/tennis.jpg')\nimg1 <- readJPEG('images/ksnake.jpg')\nd = dim(img1)\nimgs = array(255*img1, dim = c(1, d[1], d[2], d[3]))\n\n# Feeding and fetching the graph\n# Now we have a graph in the session with the correct weights. We can do the predictions by feeding the placeholder tensor images with the value of the images stored in the array imgs. We fetch the fc8 tensor from the graph and store it in fc8_vals\n\nfc8_vals = sess$run(fc8, dict(images = imgs))\nfc8_vals[1:5]\n\n# we are only interested in the positive values which we transfer to probabilities for the certain classes \nprobs = exp(fc8_vals)/sum(exp(fc8_vals))\n\nidx = sort.int(fc8_vals, index.return = TRUE, decreasing = TRUE)$ix[1:5]\n\n# Reading the class names\nlibrary(readr)\nnames = read_delim(\"imagenet_classes.txt\", \"\\t\", escape_double = FALSE, col_names = FALSE)\n\n# graph\nlibrary(grid)\ng = rasterGrob(img1, interpolate=TRUE) \ntext = \"\"\nfor (id in idx) {\n  text = paste0(text, names[id,][[1]], \" \", round(probs[id],5), \"\\n\") \n}\n\nlibrary(ggplot2)\nggplot(data.frame(d=1:3)) + annotation_custom(g) + \n  annotate('text',x=0.05,y=0.05,label=text, size=7, hjust = 0, vjust=0, color='blue') + xlim(0,1) + ylim(0,1) \n\n",
    "created" : 1491122518017.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2567799494",
    "id" : "33B93C44",
    "lastKnownWriteTime" : 1491553518,
    "last_content_update" : 1491553518500,
    "path" : "C:/Users/j.kromme/Desktop/sandbox/tensorflow-playground/04 Image recognition VGG16.R",
    "project_path" : "04 Image recognition VGG16.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}